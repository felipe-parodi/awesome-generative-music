# Awesome Voice Conversion

- [Awesome Voice Conversion](#awesome-voice-conversion)
  - [Papers](#papers)
  - [Projects](#projects)


## Papers
- **StreamVoice: Streamable Context-Aware Language Modeling for Real-time
  Zero-Shot Voice Conversion**, `arXiv, 2401.11053`, [arxiv](http://arxiv.org/abs/2401.11053v2), [pdf](http://arxiv.org/pdf/2401.11053v2.pdf), cication: [**-1**](None)

	 *Zhichao Wang, Yuanzhe Chen, Xinsheng Wang, Zhuo Chen, Lei Xie, Yuping Wang, Yuxuan Wang*
- [**GPT-SoVITS**](https://github.com/RVC-Boss/GPT-SoVITS) - RVC-Boss ![Star](https://img.shields.io/github/stars/RVC-Boss/GPT-SoVITS.svg?style=social&label=Star)

	 *1 min voice data can also be used to train a good TTS model! (few shot voice cloning)*
- **CoMoSVC: Consistency Model-based Singing Voice Conversion**, `arXiv, 2401.01792`, [arxiv](http://arxiv.org/abs/2401.01792v1), [pdf](http://arxiv.org/pdf/2401.01792v1.pdf), cication: [**-1**](None)

	 *Yiwen Lu, Zhen Ye, Wei Xue, Xu Tan, Qifeng Liu, Yike Guo* · ([comosvc.github](https://comosvc.github.io/))
- **Leveraging Content-based Features from Multiple Acoustic Models for
  Singing Voice Conversion**, `arXiv, 2310.11160`, [arxiv](http://arxiv.org/abs/2310.11160v1), [pdf](http://arxiv.org/pdf/2310.11160v1.pdf), cication: [**-1**](None)

	 *Xueyao Zhang, Yicheng Gu, Haopeng Chen, Zihao Fang, Lexiao Zou, Liumeng Xue, Zhizheng Wu* · ([zhangxueyao](https://www.zhangxueyao.com/data/MultipleContentsSVC/index.html))
- [**llvc**](https://github.com/koeai/llvc) - koeai ![Star](https://img.shields.io/github/stars/koeai/llvc.svg?style=social&label=Star)
- **Rhythm Modeling for Voice Conversion**, `arXiv, 2307.06040`, [arxiv](http://arxiv.org/abs/2307.06040v1), [pdf](http://arxiv.org/pdf/2307.06040v1.pdf), cication: [**-1**](None)

	 *Benjamin van Niekerk, Marc-André Carbonneau, Herman Kamper*
- **HierVST: Hierarchical Adaptive Zero-shot Voice Style Transfer**, `arXiv, 2307.16171`, [arxiv](http://arxiv.org/abs/2307.16171v1), [pdf](http://arxiv.org/pdf/2307.16171v1.pdf), cication: [**-1**](None)

	 *Sang-Hoon Lee, Ha-Yeong Choi, Hyung-Seok Oh, Seong-Whan Lee*
- **SLMGAN: Exploiting Speech Language Model Representations for
  Unsupervised Zero-Shot Voice Conversion in GANs**, `arXiv, 2307.09435`, [arxiv](http://arxiv.org/abs/2307.09435v1), [pdf](http://arxiv.org/pdf/2307.09435v1.pdf), cication: [**-1**](None)

	 *Yinghao Aaron Li, Cong Han, Nima Mesgarani*
- **Voice Conversion With Just Nearest Neighbors**, `arXiv, 2305.18975`, [arxiv](http://arxiv.org/abs/2305.18975v1), [pdf](http://arxiv.org/pdf/2305.18975v1.pdf), cication: [**-1**](None)

	 *Matthew Baas, Benjamin van Niekerk, Herman Kamper* · ([knn-vc](https://github.com/interspeech2023blind/knn-vc) - interspeech2023blind) ![Star](https://img.shields.io/github/stars/interspeech2023blind/knn-vc.svg?style=social&label=Star) · ([bshall.github](https://bshall.github.io/knn-vc/))

## Projects

- [**Retrieval-based-Voice-Conversion-WebUI**](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI) - RVC-Project ![Star](https://img.shields.io/github/stars/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.svg?style=social&label=Star)

	 *Voice data <= 10 mins can also be used to train a good VC model!*